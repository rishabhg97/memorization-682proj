{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs682/assignments/assignment3/'\n",
        "FOLDERNAME ='Colab Notebooks/memorization-682proj/'\n",
        "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# This downloads the COCO dataset to your Drive\n",
        "# if it doesn't already exist.\n",
        "# %cd /content/drive/My\\ Drive/$FOLDERNAME/cs682/datasets/\n",
        "# !bash get_datasets.sh\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4lCjLXxjV2j",
        "outputId": "e1fba958-67e7-4f16-96f5-b54abf0c21b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/memorization-682proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYOXpUPyjvBS",
        "outputId": "128667a2-fbd6-4935-ff81-01924216adcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer,DataCollatorForLanguageModeling\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "CACHE_DIR = \"./cache\"\n",
        "if not os.path.exists(CACHE_DIR):\n",
        "    os.makedirs(CACHE_DIR)\n",
        "\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "Class SentimentAnalysisDataCollator:\n",
        "    def __call__(self, batch):\n",
        "        # Convert each item in the batch to tensors and stack them\n",
        "        input_ids = torch.stack([torch.tensor(item['input_ids']) for item in batch])\n",
        "        attention_mask = torch.stack([torch.tensor(item['attention_mask']) for item in batch])\n",
        "        labels = torch.stack([torch.tensor(item['labels']) for item in batch])\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"imdb\", '3.0.0',cache_dir=CACHE_DIR)\n",
        "# Define constants /args\n",
        "text_column ='text'\n",
        "sentiment_column ='label'\n",
        "max_source_length=100\n",
        "max_target_length=100\n",
        "ignore_pad_token_for_loss=True\n",
        "train_batch_size=16\n",
        "val_batch_size=8\n",
        "\n",
        "# Tokenize function\n",
        "def preprocess_function(examples):\n",
        "    # print(\"Original:\", examples)\n",
        "\n",
        "    inputs = examples[text_column]\n",
        "    targets = examples[sentiment_column]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding='max_length', truncation=True)\n",
        "\n",
        "    # Tokenize targets\n",
        "    labels = tokenizer(targets, max_length=max_target_length, padding='max_length', truncation=True) # might not need to tokenize since singular number of 0 or 1\n",
        "    if ignore_pad_token_for_loss:\n",
        "        # Replace pad token id (-100) where appropriate\n",
        "        labels[\"input_ids\"] = [\n",
        "            label if label != tokenizer.pad_token_id else -100 for label in labels[\"input_ids\"]\n",
        "        ]\n",
        "    # Replace padding token id in labels with -100 if ignoring pad token for loss\n",
        "    # if ignore_pad_token_for_loss:\n",
        "    #     labels[\"input_ids\"] = [\n",
        "    #         [(label if label != tokenizer.pad_token_id else -100) for label in label_ids] for label_ids in labels[\"input_ids\"]\n",
        "    #     ]\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": model_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": model_inputs[\"attention_mask\"],\n",
        "        \"labels\": labels[\"input_ids\"]\n",
        "    }\n",
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# sample_data = dataset['train'].select(range(50))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZjqzQWCdjW1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize dataset\n",
        "tokenized_dataset_path = os.path.join(CACHE_DIR, \"tokenized_dataset.pt\")\n",
        "# print(tokenized_dataset_path)\n",
        "# if os.path.exists(tokenized_dataset_path):\n",
        "#     tokenized_datasets = torch.load(tokenized_dataset_path)\n",
        "# else:\n",
        "    # Tokenize and cache dataset\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True,load_from_cache_file=True)\n",
        "print(f'Saving tokenized dataset in this path {tokenized_dataset_path}')\n",
        "torch.save(tokenized_datasets, tokenized_dataset_path)\n",
        "# tokenized_datasets = dataset.map()\n",
        "# for i, example in enumerate(tokenized_datasets):\n",
        "#     print(f\"Example {i}: {example}\")\n",
        "#     if i >= 2:  # Inspect only the first few examples\n",
        "#         break\n",
        "print(\"Dataset Columns and Keys:\")\n",
        "print(tokenized_datasets)\n",
        "# Print columns for each split (e.g., train, validation, test)\n",
        "# for split in tokenized_datasets.keys():\n",
        "#     print(f\"\\n{split} Split:\")\n",
        "#     # Print column names\n",
        "#     print(\"Columns:\", tokenized_datasets[split].column_names)\n",
        "\n",
        "#     # Optionally, print a few example keys (IDs) from the dataset\n",
        "#     print(\"Example Keys:\", [tokenized_datasets[split][i]['id'] for i in range(3)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "074425b5eba34b199be3bb380007b40f",
            "d71fa4a22886452e85dc7ebc7d85158d",
            "154a7b65ba91411bb429ca2f68828c45",
            "c4340914392d4b179830c01f28a10271",
            "2961277b11204b75acb7fb0314461bea",
            "539b2df34faf45faa2a3135fcf0d90b9",
            "e625825f954a48f9ad0cef9dfe7926a9",
            "cee8ee193693471ba38f7892109fc4c8",
            "e63498a605bd4b38bcdeadb3a5b0ede2",
            "fe78400ad3234213a2f4d998ebb23b27",
            "2b281982b4b6486cad415ce25e97811a"
          ]
        },
        "id": "KdTtxN3rlDAE",
        "outputId": "8404b228-ee48-430d-e0af-98c528c9285a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/287113 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074425b5eba34b199be3bb380007b40f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "# elif torch.backends.mps.is_available():\n",
        "#     device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "# DataLoader\n",
        "data_collator = SentimentAnalysisDataCollator()\n",
        "# data_collator = DataCollatorForLanguageModeling(\n",
        "#     tokenizer=tokenizer,\n",
        "#     mlm=False,\n",
        "# )\n",
        "# for idx, data in enumerate(tokenized_datasets['train']):\n",
        "#     print(data.keys())\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=train_batch_size,collate_fn=data_collator)\n",
        "val_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=val_batch_size,collate_fn=data_collator)\n",
        "\n",
        "# Load model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "\n",
        "# for i, batch in enumerate(train_dataloader):\n",
        "#     print(f\"Batch {i}: input_ids shape - {batch['input_ids'].shape}, attention_mask shape - {batch['attention_mask'].shape}\")\n",
        "#     if i >= 2:  # Inspect only the first few batches\n",
        "#         break\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        inputs = batch[\"input_ids\"]\n",
        "        labels = batch['labels']\n",
        "        outputs = model( inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save(model.state_dict(), f\"gpt2_imdb_epoch{epoch}.pt\")\n",
        "\n",
        "    # Evaluation (optional)\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            inputs = batch[\"input_ids\"].to(device)\n",
        "            labels = inputs.clone()\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            total_loss += outputs.loss.item()\n",
        "\n",
        "    print(f\"Validation Loss after Epoch {epoch}: {total_loss / len(val_dataloader)}\")\n",
        "\n",
        "# Save final model\n",
        "torch.save(model.state_dict(), \"gpt2_imdb_final.pt\")\n"
      ],
      "metadata": {
        "id": "NTIS77YFjo3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}